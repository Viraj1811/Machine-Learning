# -*- coding: utf-8 -*-
"""Activation_Functions

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1llAIcYaxTkSNcNC3U39cOgv-gD6Ewkvm
"""

#import basic library
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

def sigmoid(x):
  return(1/(1+np.exp(-x)))

x=np.linspace(-10,10,200)
def plot_function(x,y,title):
  plt.plot(x,y,label=title)
  plt.title(title)
  plt.show()

plot_function(x,sigmoid(x),"sigmoid")

def step_function(x):
  return np.where(x>=0,1,0)

plot_function(x,step_function(x),"Step Function")

def relu(x):
  return np.maximum(0,x)

plot_function(x,relu(x),"relu")

def linear(x):
  return x

plot_function(x,linear(x),"linear")

def Tanh(x):
  return ((np.exp(x)-np.exp(-x))/(np.exp(x)-np.exp(-x)))

plot_function(x,Tanh(x),"TanH")

def softmax(x):
  e1=(np.exp(x-np.max(x)))
  return e1/np.sum(e1,axis=0)

z=np.array([0.51,0.48,0.01])
softmax(z)

# i need to design and gate, or gate, not gate, xor gate, xnor gate, nor gate, nand gate
#identify these all => w1,w2,b,sigma_function

